version: '3'
services:
  postgres:
    image: postgres:13
    env_file:
      - .env
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-airflow}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-airflow}
      - POSTGRES_DB=${POSTGRES_DB:-airflow}
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER:-airflow}"]
      interval: 5s
      retries: 5

  airflow-init:
    image: apache/airflow:2.7.1
    env_file:
      - .env
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./include:/opt/airflow/include
      - ./tasks:/opt/airflow/tasks
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
      - ./requirements.txt:/opt/airflow/requirements.txt
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres/${POSTGRES_DB:-airflow}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - PYTHONPATH=/opt/airflow
    entrypoint: /bin/bash
    command: -c "
      pip install --user -r /opt/airflow/requirements.txt &&
      python -c \"import nltk; nltk.download('punkt'); nltk.download('stopwords')\" &&
      airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
      "

  airflow-webserver:
    image: apache/airflow:2.7.1
    restart: always
    env_file:
      - .env
    depends_on:
      - airflow-init
      - postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./include:/opt/airflow/include
      - ./tasks:/opt/airflow/tasks
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
      - ./requirements.txt:/opt/airflow/requirements.txt
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres/${POSTGRES_DB:-airflow}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_SECRET_KEY:-your_secret_key_here}
      - PYTHONPATH=/opt/airflow
    ports:
      - "8080:8080"
    command: bash -c "
      pip install --user -r /opt/airflow/requirements.txt &&
      python -c \"import nltk; nltk.download('punkt'); nltk.download('stopwords')\" &&
      airflow webserver
      "
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    image: apache/airflow:2.7.1
    restart: always
    env_file:
      - .env
    depends_on:
      - airflow-init
      - postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./include:/opt/airflow/include
      - ./tasks:/opt/airflow/tasks
      - ./plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
      - ./requirements.txt:/opt/airflow/requirements.txt
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres/${POSTGRES_DB:-airflow}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - PYTHONPATH=/opt/airflow
    command: bash -c "
      pip install --user -r /opt/airflow/requirements.txt &&
      python -c \"import nltk; nltk.download('punkt'); nltk.download('stopwords')\" &&
      airflow scheduler
      "

volumes:
  postgres-db-volume:
